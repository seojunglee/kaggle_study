{"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline","metadata":{"_cell_guid":"029ecde6-086d-7a8e-de44-363a7a23dbd8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/creditcard.csv\")\ndata.head()","metadata":{"_cell_guid":"7e5ca1e3-3597-19d2-b4be-dffd335df630"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\ncount_classes.plot(kind = 'bar')\nplt.title(\"Fraud class histogram\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\")","metadata":{"_cell_guid":"3f6e6674-12e9-6983-5788-5755f80c7ec2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndata['normAmount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1, 1))\ndata = data.drop(['Time','Amount'],axis=1)\ndata.head()","metadata":{"_cell_guid":"3fd30a6f-c0ad-5ece-943c-651cdf14d0d6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.ix[:, data.columns != 'Class']\ny = data.ix[:, data.columns == 'Class']","metadata":{"_cell_guid":"c1d874fa-5ea5-edbb-726c-ae98c84e6120"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of data points in the minority class\nnumber_records_fraud = len(data[data.Class == 1])\nfraud_indices = np.array(data[data.Class == 1].index)\n\n# Picking the indices of the normal classes\nnormal_indices = data[data.Class == 0].index\n\n# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\nrandom_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\nrandom_normal_indices = np.array(random_normal_indices)\n\n# Appending the 2 indices\nunder_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n\n# Under sample dataset\nunder_sample_data = data.iloc[under_sample_indices,:]\n\nX_undersample = under_sample_data.ix[:, under_sample_data.columns != 'Class']\ny_undersample = under_sample_data.ix[:, under_sample_data.columns == 'Class']\n\n# Showing ratio\nprint(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\nprint(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\nprint(\"Total number of transactions in resampled data: \", len(under_sample_data))","metadata":{"_cell_guid":"2af7c203-44ed-66b6-6141-ac0d0637fcc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\n\n# Whole dataset\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n\nprint(\"Number transactions train dataset: \", len(X_train))\nprint(\"Number transactions test dataset: \", len(X_test))\nprint(\"Total number of transactions: \", len(X_train)+len(X_test))\n\n# Undersampled dataset\nX_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n                                                                                                   ,y_undersample\n                                                                                                   ,test_size = 0.3\n                                                                                                   ,random_state = 0)\nprint(\"\")\nprint(\"Number transactions train dataset: \", len(X_train_undersample))\nprint(\"Number transactions test dataset: \", len(X_test_undersample))\nprint(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))\n","metadata":{"_cell_guid":"4a725b16-c14a-2be8-8240-617b7b2ed8cd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report ","metadata":{"_cell_guid":"9c7ec815-da54-993b-ef8d-b41b767cfacf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def printing_Kfold_scores(x_train_data,y_train_data):\n    fold = KFold(len(y_train_data),5,shuffle=False) \n\n    # Different C parameters\n    c_param_range = [0.01,0.1,1,10,100]\n\n    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n    results_table['C_parameter'] = c_param_range\n\n    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n    j = 0\n    for c_param in c_param_range:\n        print('-------------------------------------------')\n        print('C parameter: ', c_param)\n        print('-------------------------------------------')\n        print('')\n\n        recall_accs = []\n        for iteration, indices in enumerate(fold,start=1):\n\n            # Call the logistic regression model with a certain C parameter\n            lr = LogisticRegression(C = c_param, penalty = 'l1')\n\n            # Use the training data to fit the model. In this case, we use the portion of the fold to train the model\n            # with indices[0]. We then predict on the portion assigned as the 'test cross validation' with indices[1]\n            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:].values.ravel())\n\n            # Predict values using the test indices in the training data\n            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n\n            # Calculate the recall score and append it to a list for recall scores representing the current c_parameter\n            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,y_pred_undersample)\n            recall_accs.append(recall_acc)\n            print('Iteration ', iteration,': recall score = ', recall_acc)\n\n        # The mean value of those recall scores is the metric we want to save and get hold of.\n        results_table.ix[j,'Mean recall score'] = np.mean(recall_accs)\n        j += 1\n        print('')\n        print('Mean recall score ', np.mean(recall_accs))\n        print('')\n\n    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n    \n    # Finally, we can check which C parameter is the best amongst the chosen.\n    print('*********************************************************************************')\n    print('Best model to choose from cross validation is with C parameter = ', best_c)\n    print('*********************************************************************************')\n    \n    return best_c","metadata":{"_cell_guid":"069bc837-cfd1-006e-c589-7085d5d29a8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)","metadata":{"_cell_guid":"983c1c75-8092-9a8e-40ca-754fde9e2301"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    else:\n        1#print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"_cell_guid":"f5b049b3-4f9a-f5bb-db3d-6c48e9b1e1a5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use this C_parameter to build the final model with the whole training dataset and predict the classes in the test\n# dataset\nlr = LogisticRegression(C = best_c, penalty = 'l1')\nlr.fit(X_train_undersample,y_train_undersample.values.ravel())\ny_pred_undersample = lr.predict(X_test_undersample.values)\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)\nnp.set_printoptions(precision=2)\n\nprint(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n\n# Plot non-normalized confusion matrix\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cnf_matrix\n                      , classes=class_names\n                      , title='Confusion matrix')\nplt.show()","metadata":{"_cell_guid":"5c8e4c0e-8cfd-7422-04a8-1b47b8531267"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use this C_parameter to build the final model with the whole training dataset and predict the classes in the test\n# dataset\nlr = LogisticRegression(C = best_c, penalty = 'l1')\nlr.fit(X_train_undersample,y_train_undersample.values.ravel())\ny_pred = lr.predict(X_test.values)\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test,y_pred)\nnp.set_printoptions(precision=2)\n\nprint(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n\n# Plot non-normalized confusion matrix\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cnf_matrix\n                      , classes=class_names\n                      , title='Confusion matrix')\nplt.show()","metadata":{"_cell_guid":"2fac80a6-cc45-49e8-3fd6-2322e2461955"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC CURVE\nlr = LogisticRegression(C = best_c, penalty = 'l1')\ny_pred_undersample_score = lr.fit(X_train_undersample,y_train_undersample.values.ravel()).decision_function(X_test_undersample.values)\n\nfpr, tpr, thresholds = roc_curve(y_test_undersample.values.ravel(),y_pred_undersample_score)\nroc_auc = auc(fpr,tpr)\n\n# Plot ROC\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.0])\nplt.ylim([-0.1,1.01])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","metadata":{"_cell_guid":"4a0d3339-cb16-5899-0b0e-f86636284a63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_c = printing_Kfold_scores(X_train,y_train)","metadata":{"_cell_guid":"2aaf245f-43cd-d543-b857-562fb696fc4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use this C_parameter to build the final model with the whole training dataset and predict the classes in the test\n# dataset\nlr = LogisticRegression(C = best_c, penalty = 'l1')\nlr.fit(X_train,y_train.values.ravel())\ny_pred_undersample = lr.predict(X_test.values)\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test,y_pred_undersample)\nnp.set_printoptions(precision=2)\n\nprint(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n\n# Plot non-normalized confusion matrix\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cnf_matrix\n                      , classes=class_names\n                      , title='Confusion matrix')\nplt.show()","metadata":{"_cell_guid":"634c1907-a5c5-888c-c2e9-da73f81ee445"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression(C = 0.01, penalty = 'l1')\nlr.fit(X_train_undersample,y_train_undersample.values.ravel())\ny_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)\n\nthresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n\nplt.figure(figsize=(10,10))\n\nj = 1\nfor i in thresholds:\n    y_test_predictions_high_recall = y_pred_undersample_proba[:,1] > i\n    \n    plt.subplot(3,3,j)\n    j += 1\n    \n    # Compute confusion matrix\n    cnf_matrix = confusion_matrix(y_test_undersample,y_test_predictions_high_recall)\n    np.set_printoptions(precision=2)\n\n    print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n\n    # Plot non-normalized confusion matrix\n    class_names = [0,1]\n    plot_confusion_matrix(cnf_matrix\n                          , classes=class_names\n                          , title='Threshold >= %s'%i) ","metadata":{"_cell_guid":"a1275e7d-48fc-e0bd-c629-6ddf698b47b5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import cycle\n\nlr = LogisticRegression(C = 0.01, penalty = 'l1')\nlr.fit(X_train_undersample,y_train_undersample.values.ravel())\ny_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)\n\nthresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\ncolors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal', 'red', 'yellow', 'green', 'blue','black'])\n\nplt.figure(figsize=(5,5))\n\nj = 1\nfor i,color in zip(thresholds,colors):\n    y_test_predictions_prob = y_pred_undersample_proba[:,1] > i\n    \n    precision, recall, thresholds = precision_recall_curve(y_test_undersample,y_test_predictions_prob)\n    \n    # Plot Precision-Recall curve\n    plt.plot(recall, precision, color=color,\n                 label='Threshold: %s'%i)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    plt.title('Precision-Recall example')\n    plt.legend(loc=\"lower left\")","metadata":{"_cell_guid":"c73b727b-6743-add2-a45f-a83ce5b8b375"},"execution_count":null,"outputs":[]}]}
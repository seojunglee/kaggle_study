{"metadata":{"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","name":"python","version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom os.path import join as opj\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport pylab\nplt.rcParams['figure.figsize'] = 10, 10\n%matplotlib inline","metadata":{"_uuid":"58c82d3b3c4b4305b388a6ac4eeca49d600f9105","_cell_guid":"ea3f4874-a9aa-42f1-9605-b1784a6f48ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load the data.\ntrain = pd.read_json(\"../input/train.json\")","metadata":{"_uuid":"7a7f3af5ef279a9ed26c4d9ee764bd1fb4bdf10e","_cell_guid":"804d3969-9035-4ceb-bb65-1b8549d729ec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_json(\"../input/test.json\")","metadata":{"_uuid":"2c18cf164fbbc6d1c29e9c668cbfcd7a1ea10824","_cell_guid":"7b546aab-7b7d-4cde-91cc-e794fd4041bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Generate the training data\n#Create 3 bands having HH, HV and avg of both\nX_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nX_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\nX_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)","metadata":{"_uuid":"5292632717f11cd01c135dfabfd3cda9318cc639","_cell_guid":"829bf7db-fab1-4a2d-9562-0a37c6390d2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Take a look at a iceberg\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\ndef plotmy3d(c, name):\n\n    data = [\n        go.Surface(\n            z=c\n        )\n    ]\n    layout = go.Layout(\n        title=name,\n        autosize=False,\n        width=700,\n        height=700,\n        margin=dict(\n            l=65,\n            r=50,\n            b=65,\n            t=90\n        )\n    )\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig)\nplotmy3d(X_band_1[12,:,:], 'iceberg')","metadata":{"_uuid":"01b69c50c6425d7d35b9bbefca7c06ea4bf1214b","_cell_guid":"a95eedd5-fc75-4834-a817-e3ad700923f5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotmy3d(X_band_1[14,:,:], 'Ship')","metadata":{"_uuid":"ab163fd947f3f108eacb0d367bf62505b0b9df9b","_cell_guid":"f78d43c6-c83e-47e3-a279-4dc8d3481c6c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import Keras.\nfrom matplotlib import pyplot\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras import initializers\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping","metadata":{"_uuid":"7a68a94f8c617209dfe56a58e291193e963d0f62","_cell_guid":"fb15bc53-becc-4e87-88ce-3bc99d45358d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define our model\ndef getModel():\n    #Building the model\n    gmodel=Sequential()\n    #Conv Layer 1\n    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n    gmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 2\n    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 3\n    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 4\n    gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Flatten the data for upcoming dense layers\n    gmodel.add(Flatten())\n\n    #Dense Layers\n    gmodel.add(Dense(512))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Dropout(0.2))\n\n    #Dense Layer 2\n    gmodel.add(Dense(256))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Dropout(0.2))\n\n    #Sigmoid Layer\n    gmodel.add(Dense(1))\n    gmodel.add(Activation('sigmoid'))\n\n    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n    gmodel.compile(loss='binary_crossentropy',\n                  optimizer=mypotim,\n                  metrics=['accuracy'])\n    gmodel.summary()\n    return gmodel\n\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\nfile_path = \".model_weights.hdf5\"\ncallbacks = get_callbacks(filepath=file_path, patience=5)\n","metadata":{"_uuid":"4602792c9d531903bd65c3b127a1e6be2c444b2d","_cell_guid":"d7a4c0cc-0e96-46ea-960c-89bb80e11b56"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_train=train['is_iceberg']\nX_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=1, train_size=0.75)","metadata":{"_uuid":"a883659e53709da950d04a4e5349c66d77a9422f","_cell_guid":"1d690d4a-09ca-417c-8090-2aa417c514dd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Without denoising, core features.\nimport os\ngmodel=getModel()\ngmodel.fit(X_train_cv, y_train_cv,\n          batch_size=24,\n          epochs=50,\n          verbose=1,\n          validation_data=(X_valid, y_valid),\n          callbacks=callbacks)","metadata":{"_uuid":"4e6dab11165b7d9515eb32b698851b260f0d941f","_cell_guid":"d6bb750a-e882-4429-ad23-4392389f427f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###Though the score may be different here,  it works good on LB, I got 0.210 score.","metadata":{"_uuid":"04da75db4d60b76ae357503ea1178808e1026b56","_cell_guid":"923850b1-707e-41e7-bdcb-b5d0633fb12f"}},{"cell_type":"code","source":"gmodel.load_weights(filepath=file_path)\nscore = gmodel.evaluate(X_valid, y_valid, verbose=1)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"_uuid":"0fa65f37d198cd6301376f179d9de0ccc1d40db3","_cell_guid":"079f0a8d-d2a5-4154-b37f-b425333e4ada"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nX_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\nX_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n                          , X_band_test_2[:, :, :, np.newaxis]\n                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\npredicted_test=gmodel.predict_proba(X_test)","metadata":{"_uuid":"27f021784da863a2ad960a96b9c7394f25521802","_cell_guid":"7cae1458-a566-4714-8b80-0b23fe88509c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['id']=test['id']\nsubmission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\nsubmission.to_csv('sub.csv', index=False)","metadata":{"_uuid":"b34412c33fe8250df3285867d9a13e4bd08e8c12","_cell_guid":"da3618f6-6e0a-475c-a390-7e17f5406c1a"},"execution_count":null,"outputs":[]}]}